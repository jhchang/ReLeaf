{"cells":[{"metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"},"cell_type":"markdown","source":"Import neccessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nimport keras\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.applications import InceptionV3\nfrom keras.models       import Model\nfrom keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c3354a78e21a1a62ad0c4689d0ab3238fb760d4"},"cell_type":"code","source":"EPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\nBATCH_SIZE = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '../input/plantdisease/'\nwidth=256\nheight=256\ndepth=3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bf7ac0a0b805946f844a48e55d5281403e53f57"},"cell_type":"markdown","source":"Function to convert images to array"},{"metadata":{"trusted":true,"_uuid":"c9c3e60b13ace6c8f3e54336e12f9970fde438a3"},"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(listdir(\"../input/plantdisease\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"},"cell_type":"markdown","source":"Fetch images from directory"},{"metadata":{"trusted":true,"_uuid":"bb8d4c343314028f52ae3c3a840478a834a16c95"},"cell_type":"code","source":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n\n            for image in plant_disease_image_list[:200]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35c4b76d33e0263523e479657580104532f81d6e"},"cell_type":"markdown","source":"Get Size of Processed Image"},{"metadata":{"trusted":true,"_uuid":"6ee1ad9c422f112ec2862699b5c0f68b8d658123"},"cell_type":"code","source":"image_size = len(image_list)\nprint(image_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"905b41b226f3fd82a88e67821eb42a07f24b31f7"},"cell_type":"markdown","source":"Transform Image Labels uisng [Scikit Learn](http://scikit-learn.org/)'s LabelBinarizer"},{"metadata":{"trusted":true,"_uuid":"904ff893fe14f5060dd9e7be2ccf96ec793597e5"},"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f860c29a1d714f06d25e6a0c5bca94739e5d24cc"},"cell_type":"markdown","source":"Print the classes"},{"metadata":{"trusted":true,"_uuid":"0f876397c40c3c8aa09772a92fd60481fc9ba268"},"cell_type":"code","source":"print(label_binarizer.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cd9c977b3d164a5570a0c24fdd8624adb9d56b8"},"cell_type":"code","source":"np_image_list = np.array(image_list, dtype=np.float16) / 225.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f4829560fdfa218cee18c1cfb2eb9452ef180e5"},"cell_type":"code","source":"print(\"[INFO] Spliting data to train, validation, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state=1)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train generator.\ntrain_datagen = ImageDataGenerator(rescale=1./255, \n                                   rotation_range=30, \n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2, \n                                   horizontal_flip = 'true')\ntrain_generator = train_datagen.flow(x_train, y_train, shuffle=False, \n                                     batch_size=BATCH_SIZE, seed=1)\n                                     \n# Create validation generator\nval_datagen = ImageDataGenerator(rescale = 1./255)\nval_generator = train_datagen.flow(x_val, y_val, shuffle=False, \n                                   batch_size=BATCH_SIZE, seed=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the InceptionV3 model so we can do transfer learning\nbase_inception = InceptionV3(weights='imagenet', include_top=False, \n                             input_shape=(256, 256, 3))\n#try to remove the input_shape argument\n#maybe add regularization\nout = base_inception.output\nout = layers.GlobalAveragePooling2D()(out)\nout = Dense(512, activation='relu')(out)\nout = Dense(512, activation='relu')(out)\ntotal_classes = n_classes\npredictions = Dense(total_classes, activation='softmax')(out)\n\nmodel = Model(inputs=base_inception.input, outputs=predictions)\n\n# only if we want to freeze layers\nfor layer in base_inception.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy']) \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = BATCH_SIZE\ntrain_steps_per_epoch = x_train.shape[0] // batch_size\nval_steps_per_epoch = x_val.shape[0] // batch_size\n\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    validation_data=(x_val, y_val),\n                    epochs=10,\n                    batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch_size = BATCH_SIZE\n# train_steps_per_epoch = x_train.shape[0] // batch_size\n# val_steps_per_epoch = x_val.shape[0] // batch_size\n\n# history = model.fit_generator(train_generator,\n#                               steps_per_epoch=train_steps_per_epoch,\n#                               validation_data=val_generator,\n#                               validation_steps=val_steps_per_epoch,\n#                               epochs=25, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1495fea08b37e4d4293f975ba30e6c1fc7a85ed9"},"cell_type":"markdown","source":"Plot the train and val curve"},{"metadata":{"trusted":true,"_uuid":"0af5e0f23657a4effc2d21cf8e840e81f42ec8e7"},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ca1a4489bd624c69a13cd37c0c2306ac8de55c2"},"cell_type":"markdown","source":"Model Accuracy"},{"metadata":{"trusted":true,"_uuid":"bb44f3d0b7e2862bc7d1a032612ebfd48212c1fe"},"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n    normalize:     If True, show the proportions for each category. Default is True.\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n    xyticks:       If True, show x and y ticks. Default is True.\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http://matplotlib.org/examples/color/colormaps_reference.html\n                   \n    title:         Title for the heatmap. Default is None.\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) / float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] / sum(cf[:,1])\n            recall    = cf[1,1] / sum(cf[1,:])\n            f1_score  = 2*precision*recall / (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_ohe = model.predict(x_test)\ny_pred_labels = np.argmax(y_pred_ohe, axis=1)\ny_true_labels = np.argmax(y_test, axis=1)\ncf_matrix = confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\nprint(cf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = label_binarizer.classes_\nmake_confusion_matrix(cf_matrix, \n                      categories=categories, figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a1f759db8afe933e62fe4cf8332cb303bb11be8"},"cell_type":"markdown","source":"Save model using Pickle"},{"metadata":{"trusted":true,"_uuid":"5cdf06adf492d79ed28fbdc36e02ad7489c7b33e"},"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model_extra_layers.pkl', 'wb'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}